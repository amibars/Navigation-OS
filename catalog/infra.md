# Infra

> Generated from README.md on 2026-01-29
## Index
- [exo](#exo)
- [swarmnode-python](#swarmnode-python)
- [portkey-gateway](#portkey-gateway)
- [cloudflare/agents](#cloudflare-agents)
- [LLMRouter](#llmrouter)
- [ezlocalai](#ezlocalai)

---

## exo

**TL;DR:** exo: Run frontier AI locally. Maintained by exo labs.

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Distributed AI inference across devices
  - Automatic Device Discovery: Devices running exo automatically discover each other - no manual configuration.
  - RDMA over Thunderbolt: exo ships with day-0 support for RDMA over Thunderbolt 5, enabling 99% reduction in latency between devices.
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Single GPU
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: devices

### üöÄ –ó–∞–ø—É—Å–∫
```bash
pip install exo
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** Python, Node.js, Rust
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- Distributed AI inference across devices
- Automatic Device Discovery: Devices running exo automatically discover each other - no manual configuration.
- RDMA over Thunderbolt: exo ships with day-0 support for RDMA over Thunderbolt 5, enabling 99% reduction in latency between devices.
- Topology-Aware Auto Parallel: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Single GPU
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: devices

### üß≠ Fit / Maturity / Ops
- **Fit:** Distributed AI inference across devices
- **Maturity:** active
- **Latency/Cost:** quality
- **Data constraints:** devices
- **Ops friction:** low

### Full links
- Repo: https://github.com/exo-explore/exo
- Original README: https://github.com/exo-explore/exo/blob/main/README.md
- Docs: https://docs.exolabs.net

---



## swarmnode-python

**TL;DR:** The SwarmNode Python SDK provides convenient access to the SwarmNode REST API from any Python 3.8+ application. The SDK includes rich type definitions and enables receiving real-time executions via WebSockets.

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Serverless AI agents
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Self-hosted only
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: API key

### üöÄ –ó–∞–ø—É—Å–∫
```bash
pip install swarmnode
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** Python
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- Serverless AI agents

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Self-hosted only
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: API key

### üß≠ Fit / Maturity / Ops
- **Fit:** Serverless AI agents
- **Maturity:** active
- **Latency/Cost:** balanced
- **Data constraints:** API key
- **Ops friction:** low

### Full links
- Repo: https://github.com/amibars/swarmnode-python
- Original README: https://github.com/amibars/swarmnode-python/blob/main/README.md
- Docs: https://swarmnode.ai/docs/sdk/introduction
- API: https://swarmnode.ai/docs/api/v1/introduction

---



## portkey-gateway

**TL;DR:** Open‚Äësource AI Gateway –æ—Ç Portkey: –µ–¥–∏–Ω—ã–π OpenAI‚Äë—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API –¥–ª—è 250+ LLM, routing, retries/fallbacks, guardrails, –∫—ç—à –∏ MCP Gateway.

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - LLM gateway + routing/guardrails
  - [x] Blazing fast (<1ms latency) with a tiny footprint (122kb)
  - [x] Battle tested, with over 10B tokens processed everyday
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Single provider
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: Provider keys

### üöÄ –ó–∞–ø—É—Å–∫
```bash
npx @portkey-ai/gateway
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** Python, JavaScript, Node.js, Go, Docker
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- LLM gateway + routing/guardrails
- [x] Blazing fast (<1ms latency) with a tiny footprint (122kb)
- [x] Battle tested, with over 10B tokens processed everyday
- [x] Enterprise-ready with enhanced security, scale, and custom deployments

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Single provider
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: Provider keys

### üß≠ Fit / Maturity / Ops
- **Fit:** LLM gateway + routing/guardrails
- **Maturity:** active
- **Latency/Cost:** fast
- **Data constraints:** Provider keys
- **Ops friction:** medium

### Full links
- Repo: https://github.com/galadriel-ai/portkey-gateway
- Original README: https://github.com/Portkey-AI/gateway/blob/main/README.md

---



## cloudflare/agents

**TL;DR:** Official framework for building and deploying AI Agents on Cloudflare Workers. Leverage Cloudflare's global edge network, serverless inference (Workers AI), and durable state (Durable Objects) for scalable, low-latency agents. 3k stars.

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - AI Agents on Cloudflare
  - Maintain persistent state and memory
  - Engage in real-time communication
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Non-Cloudflare
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: ‚Äî

### üöÄ –ó–∞–ø—É—Å–∫
```bash
# –°–º. –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: https://github.com/cloudflare/agents/blob/main/README.md
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** React
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- AI Agents on Cloudflare
- Maintain persistent state and memory
- Engage in real-time communication
- Process and learn from interactions

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Non-Cloudflare
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: ‚Äî

### üß≠ Fit / Maturity / Ops
- **Fit:** AI Agents on Cloudflare
- **Maturity:** active
- **Latency/Cost:** fast
- **Data constraints:** ‚Äî
- **Ops friction:** unknown

### Full links
- Repo: https://github.com/cloudflare/agents
- Original README: https://github.com/cloudflare/agents/blob/main/README.md
- Stars: 3,048
- Maturity: active

---



## LLMRouter

**TL;DR:** LLMRouter is an intelligent routing system designed to optimize LLM inference by dynamically selecting the most suitable model for each query. To achieve intelligent routing, it defines:

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - LLM routing library
  - ‚≠ê [2026-01]: LLMRouter just crossed 1K GitHub stars! We‚Äôve also released llmrouter-lib v0.2.0. Updates include service-specific dict configs (OpenAI, Anthropic, etc.) and multimodal routing (Video/Image + Text) on Geometry3K, MathVista, and Charades-Ego‚Äîall in the first unified open-source LLM routing library with 16+ routers, a unified CLI, Gradio UI, and 11 datasets. Install via pip install llmrouter-lib. More updates soon! üöÄ
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Single LLM
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: API keys

### üöÄ –ó–∞–ø—É—Å–∫
```bash
pip install llmrouter
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** Python, PyTorch, CUDA
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- LLM routing library
- ‚≠ê [2026-01]: LLMRouter just crossed 1K GitHub stars! We‚Äôve also released llmrouter-lib v0.2.0. Updates include service-specific dict configs (OpenAI, Anthropic, etc.) and multimodal routing (Video/Image + Text) on Geometry3K, MathVista, and Charades-Ego‚Äîall in the first unified open-source LLM routing library with 16+ routers, a unified CLI, Gradio UI, and 11 datasets. Install via pip install llmrouter-lib. More updates soon! üöÄ

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Single LLM
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: API keys

### üß≠ Fit / Maturity / Ops
- **Fit:** LLM routing library
- **Maturity:** active
- **Latency/Cost:** fast
- **Data constraints:** API keys
- **Ops friction:** low

### Full links
- Repo: https://github.com/ulab-uiuc/LLMRouter
- Original README: https://github.com/ulab-uiuc/LLMRouter/blob/main/README.md
- Stars: 1,182
- Maturity: active

---



## ezlocalai

**TL;DR:** An easy-to-setup local AI server that exposes an OpenAI-compatible API. Supports LLMs (Llama, Mistral), Vision, Speech-to-Text (Whisper), and Text-to-Speech, aiming to be a "one-click" replacement for cloud providers. 90 stars.

### –ë—ã—Å—Ç—Ä—ã–π –≤—ã–±–æ—Ä
- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Local AI server, OpenAI style
- ‚ùå –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –µ—Å–ª–∏:
  - Cloud APIs
  - –ù—É–∂–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: ‚Äî

### üöÄ –ó–∞–ø—É—Å–∫
```bash
# –°–º. –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: https://github.com/DevXT-LLC/ezlocalai
```

### üß© –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- **Category:** Infra
- **Stack:** –°–º. README
- **Entrypoints:** –°–º. README

### üß™ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á
- Local AI server, OpenAI style

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
- Cloud APIs
- –ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ/–¥–æ—Å—Ç—É–ø—ã: ‚Äî

### üß≠ Fit / Maturity / Ops
- **Fit:** Local AI server, OpenAI style
- **Maturity:** active
- **Latency/Cost:** balanced
- **Data constraints:** ‚Äî
- **Ops friction:** medium

### Full links
- Repo: https://github.com/DevXT-LLC/ezlocalai
- Stars: ~91
- Maturity: active

---
